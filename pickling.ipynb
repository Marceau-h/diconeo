{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-02T09:18:36.915218801Z",
     "start_time": "2023-05-02T09:18:32.894626300Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import lyrics as ly\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from spacy.lang.fr import French\n",
    "\n",
    "def tokenize(chaine):\n",
    "    return [token.text for token in tokenizer(chaine)]\n",
    "\n",
    "def preclean(chaine):\n",
    "    chaine = chaine.replace(u\"\\xa0\", \" \")\n",
    "    chaine = chaine.replace(u\"\\u2009\", \" \")\n",
    "    chaine = chaine.replace(u\"\\u200b\", \" \")\n",
    "    chaine = chaine.replace(u\"\\u200c\", \" \")\n",
    "    return chaine.replace(u\"\\u200d\", \" \")\n",
    "\n",
    "def clean_word(word):\n",
    "    try:\n",
    "        word = word.strip()\n",
    "    except:\n",
    "        print(word)\n",
    "        return\n",
    "    word = word.strip(\".,;“…’:!”?\\\"()[]{}«»×*\")\n",
    "    if re.fullmatch(r\"((\\\\x)|(\\\\u)|(\\\\n)|(x?\\d+)).*\", word):\n",
    "        return\n",
    "    if '\"-\"' in word:\n",
    "        return\n",
    "    if word == 'à-ç':\n",
    "        return\n",
    "    if re.fullmatch('(-\"?\\w+)|(\\w+\"?-)', word):\n",
    "        return\n",
    "    if re.fullmatch(r\"[^A-zÄ-ÿ]+\", word):\n",
    "        return\n",
    "    if re.fullmatch(r\"('+)|(\\++)\", word):\n",
    "        return\n",
    "    return word\n",
    "\n",
    "def find_neo(songs):\n",
    "    neologismes = set()\n",
    "\n",
    "    for song in songs:\n",
    "        if song.paroles:\n",
    "            paroles = tokenize(preclean(song.paroles))\n",
    "            for word in paroles:\n",
    "                word = clean_word(word)\n",
    "                if word:\n",
    "                    if word.lower() not in lexique_ultime:\n",
    "                        neologismes.add(word)\n",
    "\n",
    "    return neologismes\n",
    "\n",
    "def songs_and_neo(artiste):\n",
    "    if isinstance(artiste, str | Path):\n",
    "        artiste = ly.Artiste(artiste)\n",
    "    songs = artiste.songs\n",
    "    neologismes = find_neo(songs)\n",
    "    genres = artiste.genres\n",
    "\n",
    "    return songs, neologismes, genres\n",
    "\n",
    "nlp = French()\n",
    "\n",
    "tokenizer = nlp.tokenizer\n",
    "\n",
    "lexiques = Path(\"lexiques\").glob(\"*.json\")\n",
    "\n",
    "dict_lexiques = {\n",
    "    fic.stem: set(json.load(fic.open(encoding=\"utf-8\")))\n",
    "    for fic in lexiques\n",
    "}\n",
    "\n",
    "lexique_ultime = set.union(*dict_lexiques.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "artistes_files = Path(\"Lyrics_all\").glob(\"*.json\")\n",
    "artistes_files = sorted(artistes_files)\n",
    "\n",
    "dict_artistes = {\n",
    "    e : songs_and_neo(e)\n",
    "    for e in artistes_files\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T09:23:25.625644401Z",
     "start_time": "2023-05-02T09:18:36.918197197Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chanson_française', 'Rock'] Frank_Darcel\n"
     ]
    }
   ],
   "source": [
    "e = ly.Artiste(artistes_files[457])\n",
    "print(e.genres, e.name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T09:23:25.691131314Z",
     "start_time": "2023-05-02T09:23:25.667613246Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict_artistes).T\n",
    "df.to_pickle(\"df_artistes_raw.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T09:23:27.265717965Z",
     "start_time": "2023-05-02T09:23:25.708279871Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "neo = 50\n",
    "fr_songs = 20\n",
    "\n",
    "neover = df[df[1].apply(lambda x : len(x) > neo)]\n",
    "frver = df[df[0].apply(lambda x : len([e for e in x if e.lang == \"fr\"]) > fr_songs)]\n",
    "\n",
    "bothver = frver[frver.index.isin(neover.index)]\n",
    "\n",
    "neover.to_pickle(\"df_artistes_neo.pkl\")\n",
    "frver.to_pickle(\"df_artistes_fr.pkl\")\n",
    "bothver.to_pickle(\"df_artistes_neo_fr.pkl\")\n",
    "bothver.to_csv(\"df_artistes_neo_fr.csv\")\n",
    "bothver.to_json(\"df_artistes_neo_fr.json\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T09:23:28.188047769Z",
     "start_time": "2023-05-02T09:23:27.281109786Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                        0   \nLyrics_all/Lyrics_113.json              {[Introduction]\\nHé tonton, les cabas ils sont...  \\\nLyrics_all/Lyrics_13Block.json          {, [Paroles de \"Amis d'avant\"]\\n\\n[Intro : Zed...   \nLyrics_all/Lyrics_A2H.json              {[Couplet 1]\\nLoin des voitures vitres teintée...   \nLyrics_all/Lyrics_AgnèsBihl.json        {C'est pas la fin des haricots\\nC'est l' début...   \nLyrics_all/Lyrics_AlainSouchon.json     {, Abderhamane, Martin, David\\nEt si le ciel é...   \n...                                                                                   ...   \nLyrics_all/Lyrics_ZedYunPavarotti.json  {[Couplet 1 , Zed Yun Pavarotti]\\nJ'suis compl...   \nLyrics_all/Lyrics_ÉdithPiaf.json        {[Couplet 1]\\nJean le routier roule sur la rou...   \nLyrics_all/Lyrics_ÉlodieFrégé.json      {Ta peau chagrin m´aura manquée?\\nVers midi se...   \nLyrics_all/Lyrics_ÉricToulis.json       {[Couplet 1]\\nPourquoi dans le ciel n'y a-t-il...   \nLyrics_all/Lyrics_ÉtienneDaho.json      {, , , , , , [Couplet 1]\\nArnold Layne had a s...   \n\n                                                                                        1   \nLyrics_all/Lyrics_113.json              {tchourai, K-1, k'1, X4, Tahar, Zidane, Wailo,...  \\\nLyrics_all/Lyrics_13Block.json          {coucoune, IK2, Debo, aplis, Yeuz, vwé', prem'...   \nLyrics_all/Lyrics_A2H.json              {l''tur, rnouch, michtos, exites, en-dessous, ...   \nLyrics_all/Lyrics_AgnèsBihl.json        {j´mens, b´soin, nanère, d´fer, dollards, qu´t...   \nLyrics_all/Lyrics_AlainSouchon.json     {Messahoud, Abderhamane, Laperla, lullaby, Int...   \n...                                                                                   ...   \nLyrics_all/Lyrics_ZedYunPavarotti.json  {siques, Pavarroti, barbec, everyday, KDM, Shi...   \nLyrics_all/Lyrics_ÉdithPiaf.json        {hear, él', en-dessous, poussi?reux, costum', ...   \nLyrics_all/Lyrics_ÉlodieFrégé.json      {J´ai, d´avoir, s´élève, Oresque, qu´on, d´or,...   \nLyrics_all/Lyrics_ÉricToulis.json       {Kanter, Patapizza, intermittière, passr', r’p...   \nLyrics_all/Lyrics_ÉtienneDaho.json      {crying, d´m´élever, answer, seduz, Désadorer,...   \n\n                                                                                        2  \nLyrics_all/Lyrics_113.json                                    [Hip-hop, Hip-hop_français]  \nLyrics_all/Lyrics_13Block.json                                                         []  \nLyrics_all/Lyrics_A2H.json                                                             []  \nLyrics_all/Lyrics_AgnèsBihl.json                                                       []  \nLyrics_all/Lyrics_AlainSouchon.json                                   [Chanson_française]  \n...                                                                                   ...  \nLyrics_all/Lyrics_ZedYunPavarotti.json  [Chanson_française, Cloud_rap, Pop_(musique), ...  \nLyrics_all/Lyrics_ÉdithPiaf.json           [Chanson_française, Chanson_réaliste, Q805130]  \nLyrics_all/Lyrics_ÉlodieFrégé.json                                                     []  \nLyrics_all/Lyrics_ÉricToulis.json                                     [Chanson_française]  \nLyrics_all/Lyrics_ÉtienneDaho.json      [Electro, New_wave, Pop_(musique), Pop_psychéd...  \n\n[157 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Lyrics_all/Lyrics_113.json</th>\n      <td>{[Introduction]\\nHé tonton, les cabas ils sont...</td>\n      <td>{tchourai, K-1, k'1, X4, Tahar, Zidane, Wailo,...</td>\n      <td>[Hip-hop, Hip-hop_français]</td>\n    </tr>\n    <tr>\n      <th>Lyrics_all/Lyrics_13Block.json</th>\n      <td>{, [Paroles de \"Amis d'avant\"]\\n\\n[Intro : Zed...</td>\n      <td>{coucoune, IK2, Debo, aplis, Yeuz, vwé', prem'...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>Lyrics_all/Lyrics_A2H.json</th>\n      <td>{[Couplet 1]\\nLoin des voitures vitres teintée...</td>\n      <td>{l''tur, rnouch, michtos, exites, en-dessous, ...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>Lyrics_all/Lyrics_AgnèsBihl.json</th>\n      <td>{C'est pas la fin des haricots\\nC'est l' début...</td>\n      <td>{j´mens, b´soin, nanère, d´fer, dollards, qu´t...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>Lyrics_all/Lyrics_AlainSouchon.json</th>\n      <td>{, Abderhamane, Martin, David\\nEt si le ciel é...</td>\n      <td>{Messahoud, Abderhamane, Laperla, lullaby, Int...</td>\n      <td>[Chanson_française]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Lyrics_all/Lyrics_ZedYunPavarotti.json</th>\n      <td>{[Couplet 1 , Zed Yun Pavarotti]\\nJ'suis compl...</td>\n      <td>{siques, Pavarroti, barbec, everyday, KDM, Shi...</td>\n      <td>[Chanson_française, Cloud_rap, Pop_(musique), ...</td>\n    </tr>\n    <tr>\n      <th>Lyrics_all/Lyrics_ÉdithPiaf.json</th>\n      <td>{[Couplet 1]\\nJean le routier roule sur la rou...</td>\n      <td>{hear, él', en-dessous, poussi?reux, costum', ...</td>\n      <td>[Chanson_française, Chanson_réaliste, Q805130]</td>\n    </tr>\n    <tr>\n      <th>Lyrics_all/Lyrics_ÉlodieFrégé.json</th>\n      <td>{Ta peau chagrin m´aura manquée?\\nVers midi se...</td>\n      <td>{J´ai, d´avoir, s´élève, Oresque, qu´on, d´or,...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>Lyrics_all/Lyrics_ÉricToulis.json</th>\n      <td>{[Couplet 1]\\nPourquoi dans le ciel n'y a-t-il...</td>\n      <td>{Kanter, Patapizza, intermittière, passr', r’p...</td>\n      <td>[Chanson_française]</td>\n    </tr>\n    <tr>\n      <th>Lyrics_all/Lyrics_ÉtienneDaho.json</th>\n      <td>{, , , , , , [Couplet 1]\\nArnold Layne had a s...</td>\n      <td>{crying, d´m´élever, answer, seduz, Désadorer,...</td>\n      <td>[Electro, New_wave, Pop_(musique), Pop_psychéd...</td>\n    </tr>\n  </tbody>\n</table>\n<p>157 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bothver\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T09:23:28.223316501Z",
     "start_time": "2023-05-02T09:23:28.215944216Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
